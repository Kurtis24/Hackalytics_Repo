{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Arbitrage Window Detection with Deep Learning\n",
    "\n",
    "In this notebook, we train a **Dual-Stream Transformer Encoder with Cross-Attention** on historical odds data to identify opportunities for arbitrage betting.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The model processes paired sequences of odds from two bookmakers through:\n",
    "1. **Feature Engineering** — raw odds, spread, implied probability difference, rate of change, classical arbitrage indicator\n",
    "2. **Dual Transformer Encoders** — one per bookmaker stream, with self-attention + cross-attention\n",
    "3. **Attention-Weighted Pooling** — aggregates variable-length sequences (longer = more accurate)\n",
    "4. **Market Type Embedding** — conditions the scorer on MONEYLINE / POINTS_SPREAD / POINTS_TOTAL\n",
    "5. **MLP Scoring Head** — outputs a scalar arbitrage opportunity score in [0, 1]\n",
    "\n",
    "This tutorial covers the full lifecycle: data generation, model design, training, hyperparameter tuning, MLflow logging, registration, and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "(Optional) Install the latest version of MLflow"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq mlflow pytorch-lightning optuna skorch uv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional, Dict, List, Any\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import Metric, Param\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0. Configure the Model Registry with Unity Catalog\n",
    "\n",
    "Configure MLflow to use Unity Catalog for model registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "mlflow.set_registry_uri(\"databricks-uc\")\n\nVOLUME_PATH = \"/Volumes/workspace/default/hacklytics_project_storage\""
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "## 0a. Create Delta Tables and Load Parquet Data\n\nRun the table creation script, then read parquet files from the Databricks Volume\nand write them into the `upcoming_games` and `game_odds` Delta tables."
  },
  {
   "cell_type": "code",
   "source": "# ── Create Delta tables ──────────────────────────────────────────────────────\n%run ../scripts/create_delta_tables",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import os\nfrom functools import reduce\nfrom pyspark.sql import DataFrame, functions as F\n\ndef read_volume_parquets(spark, volume_path: str, prefix: str) -> DataFrame:\n    \"\"\"Read all parquet files in a volume whose names start with `prefix`.\n\n    Handles the case where there are multiple files sharing a common prefix\n    (e.g. events.parquet, events_nba.parquet, events_nfl_2024-25.parquet).\n    \"\"\"\n    all_files = dbutils.fs.ls(volume_path)\n    matched = [\n        f.path for f in all_files\n        if f.name.startswith(prefix) and f.name.endswith(\".parquet\")\n    ]\n    if not matched:\n        raise FileNotFoundError(\n            f\"No parquet files with prefix '{prefix}' found in {volume_path}\"\n        )\n    print(f\"  Found {len(matched)} file(s) for '{prefix}': {[f.split('/')[-1] for f in matched]}\")\n    dfs = [spark.read.parquet(path) for path in matched]\n    return reduce(DataFrame.unionByName, dfs)\n\n# ── Read parquet files from the volume ───────────────────────────────────────\nprint(f\"Reading parquet files from {VOLUME_PATH} ...\")\nevents_df = read_volume_parquets(spark, VOLUME_PATH, \"events\")\nopening_df = read_volume_parquets(spark, VOLUME_PATH, \"opening\")\nclosing_df = read_volume_parquets(spark, VOLUME_PATH, \"closing\")\n\nprint(f\"\\nEvents:  {events_df.count()} rows\")\nprint(f\"Opening: {opening_df.count()} rows\")\nprint(f\"Closing: {closing_df.count()} rows\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ── Cast timestamp columns from string ───────────────────────────────────────\ntimestamp_cols = [\"event_start_time\", \"competition_instance_start\", \"competition_instance_end\"]\n\nfor col_name in timestamp_cols:\n    events_df = events_df.withColumn(col_name, F.to_timestamp(col_name))\n    opening_df = opening_df.withColumn(col_name, F.to_timestamp(col_name))\n    closing_df = closing_df.withColumn(col_name, F.to_timestamp(col_name))\n\nodds_timestamp_cols = [\"read_at\", \"last_found_at\"]\nfor col_name in odds_timestamp_cols:\n    opening_df = opening_df.withColumn(col_name, F.to_timestamp(col_name))\n    closing_df = closing_df.withColumn(col_name, F.to_timestamp(col_name))\n\n# ── Write events → upcoming_games ───────────────────────────────────────────\nupcoming_games_df = events_df.filter(\n    F.col(\"event_start_time\") > F.current_timestamp()\n)\n\nupcoming_games_df.write.mode(\"overwrite\").saveAsTable(\"default.upcoming_games\")\nprint(f\"Wrote {upcoming_games_df.count()} rows to upcoming_games\")\n\n# ── Combine opening + closing odds → game_odds ──────────────────────────────\nopening_tagged = opening_df.withColumn(\"odds_type\", F.lit(\"opening\"))\nclosing_tagged = closing_df.withColumn(\"odds_type\", F.lit(\"closing\"))\nall_odds_df = opening_tagged.unionByName(closing_tagged)\n\nall_odds_df.write.mode(\"overwrite\").saveAsTable(\"default.game_odds\")\nprint(f\"Wrote {all_odds_df.count()} rows to game_odds\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ── Verify Delta tables ──────────────────────────────────────────────────────\nprint(\"=== upcoming_games ===\")\nspark.table(\"default.upcoming_games\").printSchema()\nspark.table(\"default.upcoming_games\").show(5, truncate=False)\n\nprint(\"=== game_odds ===\")\nspark.table(\"default.game_odds\").printSchema()\nspark.table(\"default.game_odds\").show(5, truncate=False)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ── Load Delta tables into pandas for model training ─────────────────────────\nX_events = spark.table(\"default.upcoming_games\").toPandas()\nX_odds = spark.table(\"default.game_odds\").toPandas()\n\nX_open_odds = X_odds[X_odds[\"odds_type\"] == \"opening\"].copy()\nX_end_odds = X_odds[X_odds[\"odds_type\"] == \"closing\"].copy()\n\nprint(f\"Events (upcoming): {len(X_events)} rows\")\nprint(f\"Opening odds:      {len(X_open_odds)} rows\")\nprint(f\"Closing odds:      {len(X_end_odds)} rows\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "## 1. Build Training Data\n\nWe combine **real odds from Delta tables** (opening → closing sequences per bookmaker pair)\nwith **synthetic data** to produce a robust training set. Each sample is a variable-length\ntime series of decimal odds from two bookmakers for a single event and market type."
  },
  {
   "cell_type": "code",
   "source": "from itertools import combinations\n\ndef build_real_odds_samples(\n    open_odds: pd.DataFrame,\n    close_odds: pd.DataFrame,\n) -> List[Dict[str, Any]]:\n    \"\"\"Convert real opening/closing odds into training samples.\n\n    For each (event, market_type) group, we find all bookmaker sources,\n    form every pair, and build a 2-point time series [opening, closing]\n    for each bookmaker in the pair. The arbitrage label is determined by\n    whether the sum of implied probabilities drops below 1 at either the\n    opening or closing snapshot.\n    \"\"\"\n    # Join opening and closing odds on the natural key\n    join_cols = [\"event_key\", \"market_type\", \"source\", \"participant_key\"]\n    merged = open_odds.merge(\n        close_odds,\n        on=join_cols,\n        suffixes=(\"_open\", \"_close\"),\n        how=\"inner\",\n    )\n\n    if merged.empty:\n        print(\"Warning: no matching open/close odds pairs found.\")\n        return []\n\n    samples = []\n    # Group by event + market_type to find bookmaker pairs\n    for (event_key, market_type), group in merged.groupby([\"event_key\", \"market_type\"]):\n        sources = group[\"source\"].unique()\n        if len(sources) < 2:\n            continue\n\n        # Map market_type strings to the model's expected categories\n        mt = market_type.upper()\n        if mt not in (\"MONEYLINE\", \"POINTS_SPREAD\", \"POINTS_TOTAL\"):\n            continue\n\n        for src_a, src_b in combinations(sources, 2):\n            rows_a = group[group[\"source\"] == src_a]\n            rows_b = group[group[\"source\"] == src_b]\n\n            if rows_a.empty or rows_b.empty:\n                continue\n\n            # Use the first participant row for each source to get payout\n            row_a = rows_a.iloc[0]\n            row_b = rows_b.iloc[0]\n\n            # Build 2-point sequences: [opening_payout, closing_payout]\n            odds_a = np.array(\n                [row_a[\"payout_open\"], row_a[\"payout_close\"]], dtype=np.float32\n            )\n            odds_b = np.array(\n                [row_b[\"payout_open\"], row_b[\"payout_close\"]], dtype=np.float32\n            )\n\n            # Skip invalid odds (zero or negative payouts)\n            if (odds_a <= 0).any() or (odds_b <= 0).any():\n                continue\n\n            # Determine arbitrage label: sum of implied probs < 1 at any timestep\n            impl_sum = (1.0 / odds_a) + (1.0 / odds_b)\n            has_arb = float((impl_sum < 1.0).any())\n\n            samples.append({\n                \"odds_a\": odds_a,\n                \"odds_b\": odds_b,\n                \"market_type\": mt,\n                \"label\": has_arb,\n                \"seq_len\": 2,\n            })\n\n    return samples\n\n\nreal_data = build_real_odds_samples(X_open_odds, X_end_odds)\nn_real_arb = sum(1 for s in real_data if s[\"label\"] == 1.0)\nprint(f\"Real data samples: {len(real_data)}\")\nprint(f\"  Arbitrage:     {n_real_arb} ({n_real_arb / max(len(real_data), 1):.1%})\")\nprint(f\"  No arbitrage:  {len(real_data) - n_real_arb}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 8"
    }
   },
   "outputs": [],
   "source": "def generate_synthetic_odds_data(\n    n_samples: int = 3000,\n    min_seq_len: int = 10,\n    max_seq_len: int = 120,\n    seed: int = 42,\n    arb_fraction: float = 0.3,\n) -> List[Dict[str, Any]]:\n    \"\"\"Generate synthetic paired odds sequences for two bookmakers.\n\n    Each sample contains:\n        - odds_a: sequence of American odds from bookmaker A\n        - odds_b: sequence of American odds from bookmaker B (complementary side)\n        - market_type: one of {MONEYLINE, POINTS_SPREAD, POINTS_TOTAL}\n        - label: 1 if an arbitrage window existed, 0 otherwise\n        - seq_len: length of the sequence\n\n    The generator simulates realistic odds dynamics where bookmakers move\n    asynchronously and occasionally create short-lived arbitrage windows.\n    \"\"\"\n    rng = np.random.RandomState(seed)\n    market_types = [\"MONEYLINE\", \"POINTS_SPREAD\", \"POINTS_TOTAL\"]\n    samples = []\n\n    for i in range(n_samples):\n        seq_len = rng.randint(min_seq_len, max_seq_len + 1)\n        market = rng.choice(market_types)\n        has_arb = rng.random() < arb_fraction\n\n        # Base implied probabilities for the two sides of a bet\n        # (e.g., Team A win vs Team B win for moneyline)\n        true_prob_a = rng.uniform(0.30, 0.70)\n        true_prob_b = 1.0 - true_prob_a\n\n        # Bookmaker vigorish (overround) — typically 3-8%\n        vig_a = rng.uniform(0.03, 0.08)\n        vig_b = rng.uniform(0.03, 0.08)\n\n        # Generate odds sequences as implied probabilities with random walk\n        implied_a = np.zeros(seq_len)  # bookmaker A implied prob for side A\n        implied_b = np.zeros(seq_len)  # bookmaker B implied prob for side B\n\n        implied_a[0] = true_prob_a + vig_a + rng.normal(0, 0.02)\n        implied_b[0] = true_prob_b + vig_b + rng.normal(0, 0.02)\n\n        # Correlated random walks with bookmaker-specific lag\n        drift_a = rng.normal(0, 0.005, seq_len)\n        drift_b = rng.normal(0, 0.005, seq_len)\n\n        # Bookmaker B may lag behind market moves\n        lag = rng.randint(1, 4)\n        common_shock = rng.normal(0, 0.008, seq_len)\n\n        for t in range(1, seq_len):\n            implied_a[t] = implied_a[t-1] + drift_a[t] + common_shock[t]\n            lagged_shock = common_shock[max(0, t - lag)]\n            implied_b[t] = implied_b[t-1] + drift_b[t] + lagged_shock\n\n        # Clamp to valid probability range\n        implied_a = np.clip(implied_a, 0.15, 0.95)\n        implied_b = np.clip(implied_b, 0.15, 0.95)\n\n        # Inject arbitrage window for positive samples\n        if has_arb:\n            arb_start = rng.randint(seq_len // 3, 2 * seq_len // 3)\n            arb_duration = rng.randint(2, min(8, seq_len - arb_start))\n            # Make sum of implied probs < 1 (arbitrage condition)\n            for t in range(arb_start, min(arb_start + arb_duration, seq_len)):\n                gap = rng.uniform(0.01, 0.04)\n                implied_a[t] = true_prob_a - gap / 2\n                implied_b[t] = true_prob_b - gap / 2\n\n        # Convert implied probabilities to decimal odds\n        odds_a = 1.0 / implied_a\n        odds_b = 1.0 / implied_b\n\n        samples.append({\n            \"odds_a\": odds_a.astype(np.float32),\n            \"odds_b\": odds_b.astype(np.float32),\n            \"market_type\": market,\n            \"label\": float(has_arb),\n            \"seq_len\": seq_len,\n        })\n\n    return samples\n\n\nsynthetic_data = generate_synthetic_odds_data(n_samples=4000, seed=42)\nprint(f\"Synthetic samples: {len(synthetic_data)}\")\nprint(f\"  Label distribution: {sum(s['label'] for s in synthetic_data) / len(synthetic_data):.1%} positive\")\nprint(f\"  Sequence length range: {min(s['seq_len'] for s in synthetic_data)} - {max(s['seq_len'] for s in synthetic_data)}\")\n\n# ── Combine real + synthetic data ────────────────────────────────────────────\nraw_data = real_data + synthetic_data\nn_total_arb = sum(1 for s in raw_data if s[\"label\"] == 1.0)\nprint(f\"\\nCombined training data: {len(raw_data)} samples\")\nprint(f\"  Real:      {len(real_data)}\")\nprint(f\"  Synthetic: {len(synthetic_data)}\")\nprint(f\"  Arbitrage: {n_total_arb} ({n_total_arb / len(raw_data):.1%})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "At each timestep we compute:\n",
    "- Raw decimal odds from both bookmakers\n",
    "- Odds spread (A − B)\n",
    "- Implied probability difference\n",
    "- Classical arbitrage indicator:  (< 1 means arbitrage)\n",
    "- Rate of change for each bookmaker\n",
    "- Time-normalized position in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimensionality per timestep: 10\n"
     ]
    }
   ],
   "source": [
    "MARKET_TYPE_MAP = {\"MONEYLINE\": 0, \"POINTS_SPREAD\": 1, \"POINTS_TOTAL\": 2}\n",
    "\n",
    "\n",
    "def engineer_features(sample: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Convert raw odds pair into an engineered feature tensor.\n",
    "\n",
    "    Returns a dict with:\n",
    "        features: np.ndarray of shape (seq_len, n_features)\n",
    "        market_type: int index\n",
    "        label: float\n",
    "        seq_len: int\n",
    "    \"\"\"\n",
    "    odds_a = sample[\"odds_a\"]\n",
    "    odds_b = sample[\"odds_b\"]\n",
    "    T = len(odds_a)\n",
    "\n",
    "    # Implied probabilities\n",
    "    impl_a = 1.0 / odds_a\n",
    "    impl_b = 1.0 / odds_b\n",
    "\n",
    "    # Classical arbitrage indicator (sum of implied probs)\n",
    "    arb_indicator = impl_a + impl_b  # < 1 means arbitrage\n",
    "\n",
    "    # Spread\n",
    "    spread = odds_a - odds_b\n",
    "\n",
    "    # Implied probability difference\n",
    "    impl_diff = impl_a - impl_b\n",
    "\n",
    "    # Rate of change (pad first element with 0)\n",
    "    delta_a = np.concatenate([[0], np.diff(odds_a)])\n",
    "    delta_b = np.concatenate([[0], np.diff(odds_b)])\n",
    "\n",
    "    # Relative rate of change\n",
    "    rel_delta_a = delta_a / (odds_a + 1e-8)\n",
    "    rel_delta_b = delta_b / (odds_b + 1e-8)\n",
    "\n",
    "    # Time position (normalized 0 to 1)\n",
    "    time_pos = np.linspace(0, 1, T).astype(np.float32)\n",
    "\n",
    "    # Stack features: (T, 10)\n",
    "    features = np.stack([\n",
    "        odds_a, odds_b,           # raw odds\n",
    "        spread, impl_diff,        # spreads\n",
    "        arb_indicator,            # arbitrage signal\n",
    "        delta_a, delta_b,         # rate of change\n",
    "        rel_delta_a, rel_delta_b, # relative rate of change\n",
    "        time_pos,                 # temporal position\n",
    "    ], axis=1).astype(np.float32)\n",
    "\n",
    "    return {\n",
    "        \"features\": features,\n",
    "        \"market_type\": MARKET_TYPE_MAP[sample[\"market_type\"]],\n",
    "        \"label\": sample[\"label\"],\n",
    "        \"seq_len\": T,\n",
    "    }\n",
    "\n",
    "\n",
    "engineered_data = [engineer_features(s) for s in raw_data]\n",
    "print(f\"Feature dimensionality per timestep: {engineered_data[0]['features'].shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Visualize the odds dynamics and feature distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA plots generated.\n"
     ]
    }
   ],
   "source": [
    "def plot_sample_odds(raw_data, idx=0):\n",
    "    \"\"\"Plot odds movement for a single sample.\"\"\"\n",
    "    s = raw_data[idx]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "    axes[0].plot(s[\"odds_a\"], label=\"Bookmaker A\", alpha=0.8)\n",
    "    axes[0].plot(s[\"odds_b\"], label=\"Bookmaker B\", alpha=0.8)\n",
    "    axes[0].set_title(f'Decimal Odds — {s[\"market_type\"]} (label={s[\"label\"]:.0f})')\n",
    "    axes[0].set_xlabel(\"Timestep\")\n",
    "    axes[0].set_ylabel(\"Decimal Odds\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    impl_sum = 1.0 / s[\"odds_a\"] + 1.0 / s[\"odds_b\"]\n",
    "    axes[1].plot(impl_sum, color=\"red\", alpha=0.8)\n",
    "    axes[1].axhline(y=1.0, color=\"green\", linestyle=\"--\", label=\"Arbitrage threshold\")\n",
    "    axes[1].set_title(\"Sum of Implied Probabilities\")\n",
    "    axes[1].set_xlabel(\"Timestep\")\n",
    "    axes[1].set_ylabel(\"Σ(1/odds)\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_feature_distributions_odds(engineered_data, n_cols=3):\n",
    "    \"\"\"Plot distributions of engineered features across all timesteps.\"\"\"\n",
    "    feature_names = [\n",
    "        \"odds_a\", \"odds_b\", \"spread\", \"impl_diff\",\n",
    "        \"arb_indicator\", \"delta_a\", \"delta_b\",\n",
    "        \"rel_delta_a\", \"rel_delta_b\", \"time_pos\"\n",
    "    ]\n",
    "    # Collect all timestep features\n",
    "    all_features = np.concatenate([s[\"features\"] for s in engineered_data], axis=0)\n",
    "    n_features = all_features.shape[1]\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(n_features):\n",
    "        sns.histplot(all_features[:, i], ax=axes[i], kde=True, color=\"skyblue\", bins=50)\n",
    "        axes[i].set_title(f\"Distribution of {feature_names[i]}\")\n",
    "\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(\"Engineered Feature Distributions\", y=1.02, fontsize=16)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_seq_length_distribution(engineered_data):\n",
    "    \"\"\"Plot distribution of sequence lengths by label.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    lens_pos = [s[\"seq_len\"] for s in engineered_data if s[\"label\"] == 1.0]\n",
    "    lens_neg = [s[\"seq_len\"] for s in engineered_data if s[\"label\"] == 0.0]\n",
    "    ax.hist(lens_neg, bins=30, alpha=0.6, label=\"No arbitrage\", color=\"steelblue\")\n",
    "    ax.hist(lens_pos, bins=30, alpha=0.6, label=\"Arbitrage\", color=\"coral\")\n",
    "    ax.set_xlabel(\"Sequence Length\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(\"Sequence Length Distribution by Label\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Generate EDA plots\n",
    "sample_plot_pos = plot_sample_odds(raw_data, idx=next(i for i, s in enumerate(raw_data) if s[\"label\"] == 1.0))\n",
    "sample_plot_neg = plot_sample_odds(raw_data, idx=next(i for i, s in enumerate(raw_data) if s[\"label\"] == 0.0))\n",
    "feat_dist_plot = plot_feature_distributions_odds(engineered_data)\n",
    "seq_len_plot = plot_seq_length_distribution(engineered_data)\n",
    "print(\"EDA plots generated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. PyTorch Dataset and Variable-Length Collation\n",
    "\n",
    "We implement a custom Dataset and a  that pads sequences to the\n",
    "longest in the batch and returns attention masks. This is critical for\n",
    "the transformer to ignore padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ArbitrageOddsDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for variable-length odds sequences.\"\"\"\n",
    "\n",
    "    def __init__(self, samples: List[Dict[str, Any]]):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        return {\n",
    "            \"features\": torch.tensor(s[\"features\"], dtype=torch.float32),\n",
    "            \"market_type\": torch.tensor(s[\"market_type\"], dtype=torch.long),\n",
    "            \"label\": torch.tensor(s[\"label\"], dtype=torch.float32),\n",
    "            \"seq_len\": s[\"seq_len\"],\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Pad variable-length sequences and create attention masks.\"\"\"\n",
    "    features = [item[\"features\"] for item in batch]\n",
    "    market_types = torch.stack([item[\"market_type\"] for item in batch])\n",
    "    labels = torch.stack([item[\"label\"] for item in batch])\n",
    "    seq_lens = torch.tensor([item[\"seq_len\"] for item in batch], dtype=torch.long)\n",
    "\n",
    "    # Pad sequences to max length in batch\n",
    "    features_padded = pad_sequence(features, batch_first=True, padding_value=0.0)\n",
    "    B, T, _ = features_padded.shape\n",
    "\n",
    "    # Create attention mask (1 = valid, 0 = padding)\n",
    "    mask = torch.arange(T).unsqueeze(0).expand(B, T) < seq_lens.unsqueeze(1)\n",
    "\n",
    "    return {\n",
    "        \"features\": features_padded,   # (B, T, F)\n",
    "        \"mask\": mask,                  # (B, T)\n",
    "        \"market_type\": market_types,   # (B,)\n",
    "        \"label\": labels,               # (B,)\n",
    "        \"seq_len\": seq_lens,           # (B,)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Dual-Stream Transformer Encoder with Cross-Attention\n",
    "\n",
    "The model architecture:\n",
    "\n",
    "\n",
    "\n",
    "Key design choices:\n",
    "- **ALiBi positional bias** for length generalization\n",
    "- **Cross-attention** in later layers for inter-bookmaker dynamics\n",
    "- **Attention-weighted pooling** so longer sequences contribute more evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ALiBiAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention with ALiBi (Attention with Linear Biases) positional encoding.\n",
    "\n",
    "    ALiBi adds a linear bias to attention scores based on query-key distance,\n",
    "    enabling strong length generalization without learned positional embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, n_heads: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Compute ALiBi slopes (one per head)\n",
    "        slopes = self._compute_slopes(n_heads)\n",
    "        self.register_buffer(\"slopes\", slopes)  # (n_heads,)\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_slopes(n_heads: int) -> torch.Tensor:\n",
    "        \"\"\"Compute ALiBi slopes following the geometric sequence from the paper.\"\"\"\n",
    "        def get_slopes_power_of_2(n):\n",
    "            start = 2 ** (-(2 ** -(math.log2(n) - 3)))\n",
    "            ratio = start\n",
    "            return [start * (ratio ** i) for i in range(n)]\n",
    "\n",
    "        if math.log2(n_heads).is_integer():\n",
    "            return torch.tensor(get_slopes_power_of_2(n_heads), dtype=torch.float32)\n",
    "        else:\n",
    "            closest_power = 2 ** math.floor(math.log2(n_heads))\n",
    "            slopes = get_slopes_power_of_2(closest_power)\n",
    "            extra = get_slopes_power_of_2(2 * closest_power)[0::2][:n_heads - closest_power]\n",
    "            return torch.tensor(slopes + extra, dtype=torch.float32)\n",
    "\n",
    "    def _alibi_bias(self, T: int) -> torch.Tensor:\n",
    "        \"\"\"Create ALiBi bias matrix of shape (n_heads, T, T).\"\"\"\n",
    "        positions = torch.arange(T, device=self.slopes.device)\n",
    "        distance = positions.unsqueeze(0) - positions.unsqueeze(1)  # (T, T)\n",
    "        bias = self.slopes.unsqueeze(-1).unsqueeze(-1) * distance.unsqueeze(0).abs().neg()\n",
    "        return bias  # (n_heads, T, T)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        query: torch.Tensor,\n",
    "        key: torch.Tensor,\n",
    "        value: torch.Tensor,\n",
    "        mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query: (B, T_q, d_model)\n",
    "            key:   (B, T_k, d_model)\n",
    "            value: (B, T_k, d_model)\n",
    "            mask:  (B, T_k) boolean mask, True=valid\n",
    "        Returns:\n",
    "            (B, T_q, d_model)\n",
    "        \"\"\"\n",
    "        B, T_q, _ = query.shape\n",
    "        T_k = key.shape[1]\n",
    "\n",
    "        Q = self.q_proj(query).view(B, T_q, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.k_proj(key).view(B, T_k, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.v_proj(value).view(B, T_k, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention + ALiBi bias\n",
    "        attn = (Q @ K.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        # Only add ALiBi bias for self-attention (T_q == T_k)\n",
    "        if T_q == T_k:\n",
    "            attn = attn + self._alibi_bias(T_q).unsqueeze(0)\n",
    "\n",
    "        # Apply padding mask\n",
    "        if mask is not None:\n",
    "            # mask: (B, T_k) -> (B, 1, 1, T_k)\n",
    "            mask_expanded = mask.unsqueeze(1).unsqueeze(2)\n",
    "            attn = attn.masked_fill(~mask_expanded, float(\"-inf\"))\n",
    "\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = (attn @ V).transpose(1, 2).contiguous().view(B, T_q, self.d_model)\n",
    "        return self.out_proj(out)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    \"\"\"Single transformer encoder layer with optional cross-attention.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1, use_cross_attn: bool = False):\n",
    "        super().__init__()\n",
    "        self.self_attn = ALiBiAttention(d_model, n_heads, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.use_cross_attn = use_cross_attn\n",
    "        if use_cross_attn:\n",
    "            self.cross_attn = ALiBiAttention(d_model, n_heads, dropout)\n",
    "            self.norm_cross = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        mask: Optional[torch.Tensor] = None,\n",
    "        cross_kv: Optional[torch.Tensor] = None,\n",
    "        cross_mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        # Self-attention\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = residual + self.self_attn(x, x, x, mask)\n",
    "\n",
    "        # Cross-attention (attend to the other bookmaker stream)\n",
    "        if self.use_cross_attn and cross_kv is not None:\n",
    "            residual = x\n",
    "            x = self.norm_cross(x)\n",
    "            x = residual + self.cross_attn(x, cross_kv, cross_kv, cross_mask)\n",
    "\n",
    "        # Feed-forward\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = residual + self.ffn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    \"\"\"Learnable attention-weighted pooling over the sequence dimension.\n",
    "\n",
    "    Longer sequences provide more evidence vectors for the pooling to attend to,\n",
    "    naturally producing more confident (and accurate) scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.query = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        self.scale = d_model ** -0.5\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, T, d_model)\n",
    "            mask: (B, T) boolean\n",
    "        Returns:\n",
    "            (B, d_model)\n",
    "        \"\"\"\n",
    "        # Compute attention scores\n",
    "        scores = (self.query * x).sum(dim=-1) * self.scale  # (B, T)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(~mask, float(\"-inf\"))\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1).unsqueeze(-1)  # (B, T, 1)\n",
    "        return (weights * x).sum(dim=1)  # (B, d_model)\n",
    "\n",
    "\n",
    "class TemporalArbitrageScorer(nn.Module):\n",
    "    \"\"\"Dual-Stream Transformer Encoder with Cross-Attention for arbitrage detection.\n",
    "\n",
    "    The input feature tensor contains both bookmaker streams stacked together.\n",
    "    The model splits them internally, processes each through its own transformer\n",
    "    stream with cross-attention in later layers, pools with learned attention\n",
    "    weights, and produces a scalar arbitrage score.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features: int = 10,\n",
    "        d_model: int = 64,\n",
    "        n_heads: int = 4,\n",
    "        n_layers: int = 3,\n",
    "        d_ff: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        n_market_types: int = 3,\n",
    "        cross_attn_start_layer: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_input_features = n_input_features\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "        # Split features: first 5 features relate more to bookmaker A, rest to B\n",
    "        # But we project the full feature vector for each stream (shared context)\n",
    "        self.proj_a = nn.Linear(n_input_features, d_model)\n",
    "        self.proj_b = nn.Linear(n_input_features, d_model)\n",
    "\n",
    "        # Market type embedding\n",
    "        self.market_emb = nn.Embedding(n_market_types, d_model)\n",
    "\n",
    "        # Transformer layers for stream A\n",
    "        self.layers_a = nn.ModuleList([\n",
    "            TransformerEncoderLayer(\n",
    "                d_model, n_heads, d_ff, dropout,\n",
    "                use_cross_attn=(i >= cross_attn_start_layer)\n",
    "            )\n",
    "            for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Transformer layers for stream B\n",
    "        self.layers_b = nn.ModuleList([\n",
    "            TransformerEncoderLayer(\n",
    "                d_model, n_heads, d_ff, dropout,\n",
    "                use_cross_attn=(i >= cross_attn_start_layer)\n",
    "            )\n",
    "            for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Attention pooling for each stream\n",
    "        self.pool_a = AttentionPooling(d_model)\n",
    "        self.pool_b = AttentionPooling(d_model)\n",
    "\n",
    "        # MLP scoring head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model * 2 + d_model, d_ff),  # concat streams + market emb\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_ff // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff // 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        features: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "        market_type: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features:    (B, T, n_input_features) padded feature tensor\n",
    "            mask:        (B, T) boolean, True = valid timestep\n",
    "            market_type: (B,) integer market type index\n",
    "        Returns:\n",
    "            (B,) arbitrage score in [0, 1]\n",
    "        \"\"\"\n",
    "        # Project into two streams\n",
    "        h_a = self.proj_a(features)  # (B, T, d_model)\n",
    "        h_b = self.proj_b(features)  # (B, T, d_model)\n",
    "\n",
    "        # Process through transformer layers with cross-attention\n",
    "        for layer_a, layer_b in zip(self.layers_a, self.layers_b):\n",
    "            h_a_new = layer_a(h_a, mask=mask, cross_kv=h_b, cross_mask=mask)\n",
    "            h_b_new = layer_b(h_b, mask=mask, cross_kv=h_a, cross_mask=mask)\n",
    "            h_a, h_b = h_a_new, h_b_new\n",
    "\n",
    "        # Pool each stream\n",
    "        pooled_a = self.pool_a(h_a, mask)  # (B, d_model)\n",
    "        pooled_b = self.pool_b(h_b, mask)  # (B, d_model)\n",
    "\n",
    "        # Market type embedding\n",
    "        m_emb = self.market_emb(market_type)  # (B, d_model)\n",
    "\n",
    "        # Concatenate and score\n",
    "        combined = torch.cat([pooled_a, pooled_b, m_emb], dim=-1)\n",
    "        score = torch.sigmoid(self.head(combined).squeeze(-1))  # (B,)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return model parameters for MLflow logging.\"\"\"\n",
    "        return {\n",
    "            \"n_input_features\": self.n_input_features,\n",
    "            \"d_model\": self.d_model,\n",
    "            \"n_heads\": self.n_heads,\n",
    "            \"n_layers\": self.n_layers,\n",
    "            \"d_ff\": self.d_ff,\n",
    "            \"dropout\": self.dropout_rate,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ArbitrageLightningModule(pl.LightningModule):\n",
    "    \"\"\"PyTorch Lightning wrapper for the TemporalArbitrageScorer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features: int = 10,\n",
    "        d_model: int = 64,\n",
    "        n_heads: int = 4,\n",
    "        n_layers: int = 3,\n",
    "        d_ff: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weight_decay: float = 1e-5,\n",
    "        cross_attn_start_layer: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = TemporalArbitrageScorer(\n",
    "            n_input_features=n_input_features,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            n_layers=n_layers,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout,\n",
    "            cross_attn_start_layer=cross_attn_start_layer,\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "\n",
    "    def forward(self, features, mask, market_type):\n",
    "        return self.model(features, mask, market_type)\n",
    "\n",
    "    def _shared_step(self, batch, stage: str):\n",
    "        scores = self(batch[\"features\"], batch[\"mask\"], batch[\"market_type\"])\n",
    "        loss = self.loss_fn(scores, batch[\"label\"])\n",
    "\n",
    "        # Metrics\n",
    "        preds = (scores > 0.5).float()\n",
    "        acc = (preds == batch[\"label\"]).float().mean()\n",
    "\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True, batch_size=len(batch[\"label\"]))\n",
    "        self.log(f\"{stage}_acc\", acc, prog_bar=True, batch_size=len(batch[\"label\"]))\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=10, T_mult=2\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "    def get_params(self) -> Dict[str, Any]:\n",
    "        return self.model.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Train / Validation / Test Split & DataLoaders\n",
    "\n",
    "We split the engineered data and create DataLoaders with our custom collate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2901\n",
      "Train: 2800, Val: 600, Test: 600\n",
      "Train positives: 28.5%\n"
     ]
    }
   ],
   "source": [
    "# Split indices\n",
    "indices = list(range(len(engineered_data)))\n",
    "labels_for_split = [s[\"label\"] for s in engineered_data]\n",
    "\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=42, stratify=labels_for_split)\n",
    "\n",
    "print(train_idx[0])\n",
    "temp_labels = [labels_for_split[i] for i in temp_idx]\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42, stratify=temp_labels)\n",
    "\n",
    "train_data = [engineered_data[i] for i in train_idx]\n",
    "\n",
    "val_data = [engineered_data[i] for i in val_idx]\n",
    "test_data = [engineered_data[i] for i in test_idx]\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "print(f\"Train positives: {sum(1 for s in train_data if s['label'] == 1.0) / len(train_data):.1%}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ArbitrageOddsDataset(train_data), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    ArbitrageOddsDataset(val_data), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    ArbitrageOddsDataset(test_data), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Standard Training Workflow\n",
    "\n",
    "Train the Temporal Arbitrage Scorer with default hyperparameters as a baseline.\n",
    "We use curriculum training — starting with shorter sequences and gradually including longer ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "💡 Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "\n",
      "  | Name    | Type                    | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------------\n",
      "0 | model   | TemporalArbitrageScorer | 4.5 K  | train | 0    \n",
      "1 | loss_fn | BCELoss                 | 0      | train | 0    \n",
      "--------------------------------------------------------------------\n",
      "4.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n",
      "135       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 175/175 [00:11<00:00, 15.24it/s, v_num=7, train_loss=0.707, train_acc=0.438, val_loss=0.692, val_acc=0.715]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 175/175 [00:11<00:00, 15.08it/s, v_num=7, train_loss=0.707, train_acc=0.438, val_loss=0.692, val_acc=0.715]\n",
      "Testing DataLoader 0: 100%|██████████| 38/38 [00:00<00:00, 65.25it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7116666436195374\n",
      "        test_loss           0.6922598481178284\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "AUC-ROC: 0.4982\n",
      "AUC-PR:  0.2920\n",
      "F1:      0.0114\n",
      "Prec:    0.2500\n",
      "Recall:  0.0058\n",
      "\n",
      "Accuracy by sequence length:\n",
      "  [ 10,  30): 0.702  (n=104)\n",
      "  [ 30,  60): 0.758  (n=157)\n",
      "  [ 60,  90): 0.696  (n=171)\n",
      "  [ 90, 121): 0.690  (n=168)\n"
     ]
    }
   ],
   "source": [
    "# Model hyperparameters\n",
    "N_INPUT_FEATURES = 10\n",
    "D_MODEL = 32\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 3\n",
    "D_FF = 256\n",
    "DROPOUT = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Create the model\n",
    "model = ArbitrageLightningModule(\n",
    "    n_input_features=N_INPUT_FEATURES,\n",
    "    d_model=D_MODEL,\n",
    "    n_heads=N_HEADS,\n",
    "    n_layers=N_LAYERS,\n",
    "    d_ff=D_FF,\n",
    "    dropout=DROPOUT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=1, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"./checkpoints\",\n",
    "    filename=\"arb-scorer-{epoch:02d}-{val_loss:.4f}\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Test\n",
    "test_results = trainer.test(model, test_loader)\n",
    "\n",
    "# Collect predictions for evaluation\n",
    "model.eval()\n",
    "all_scores = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        scores = model(batch[\"features\"], batch[\"mask\"], batch[\"market_type\"])\n",
    "        all_scores.extend(scores.cpu().numpy())\n",
    "        all_labels.extend(batch[\"label\"].cpu().numpy())\n",
    "\n",
    "all_scores = np.array(all_scores)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Calculate classification metrics\n",
    "preds_binary = (all_scores > 0.5).astype(float)\n",
    "auc_roc = roc_auc_score(all_labels, all_scores)\n",
    "auc_pr = average_precision_score(all_labels, all_scores)\n",
    "f1 = f1_score(all_labels, preds_binary)\n",
    "precision = precision_score(all_labels, preds_binary)\n",
    "recall = recall_score(all_labels, preds_binary)\n",
    "\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:  {auc_pr:.4f}\")\n",
    "print(f\"F1:      {f1:.4f}\")\n",
    "print(f\"Prec:    {precision:.4f}\")\n",
    "print(f\"Recall:  {recall:.4f}\")\n",
    "\n",
    "# Analyze accuracy by sequence length (key: longer = better)\n",
    "test_seq_lens = np.array([s[\"seq_len\"] for s in test_data])\n",
    "length_bins = [(10, 30), (30, 60), (60, 90), (90, 121)]\n",
    "print(\"\\nAccuracy by sequence length:\")\n",
    "for lo, hi in length_bins:\n",
    "    mask = (test_seq_lens >= lo) & (test_seq_lens < hi)\n",
    "    if mask.sum() > 0:\n",
    "        bin_acc = (preds_binary[mask] == all_labels[mask]).mean()\n",
    "        print(f\"  [{lo:3d}, {hi:3d}): {bin_acc:.3f}  (n={mask.sum()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation plots generated.\n"
     ]
    }
   ],
   "source": [
    "def plot_score_distribution(scores, labels):\n",
    "    \"\"\"Plot score distribution by class.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.hist(scores[labels == 0], bins=40, alpha=0.6, label=\"No arb\", color=\"steelblue\")\n",
    "    ax.hist(scores[labels == 1], bins=40, alpha=0.6, label=\"Arbitrage\", color=\"coral\")\n",
    "    ax.set_xlabel(\"Predicted Score\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(\"Score Distribution by Class\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_accuracy_by_length(scores, labels, seq_lens):\n",
    "    \"\"\"Plot accuracy vs sequence length to verify longer = better.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    preds = (scores > 0.5).astype(float)\n",
    "    correct = (preds == labels).astype(float)\n",
    "\n",
    "    # Bin by sequence length\n",
    "    bins = np.arange(10, 130, 10)\n",
    "    bin_indices = np.digitize(seq_lens, bins)\n",
    "    bin_accs = []\n",
    "    bin_centers = []\n",
    "    for b in range(1, len(bins)):\n",
    "        mask = bin_indices == b\n",
    "        if mask.sum() > 5:\n",
    "            bin_accs.append(correct[mask].mean())\n",
    "            bin_centers.append((bins[b-1] + bins[b]) / 2)\n",
    "\n",
    "    ax.plot(bin_centers, bin_accs, \"o-\", color=\"teal\", markersize=8)\n",
    "    ax.set_xlabel(\"Sequence Length\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Accuracy vs Sequence Length (Longer → Better)\")\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "score_dist_plot = plot_score_distribution(all_scores, all_labels)\n",
    "acc_by_len_plot = plot_accuracy_by_length(all_scores, all_labels, test_seq_lens)\n",
    "print(\"Evaluation plots generated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. Log the Model with MLflow\n",
    "\n",
    "Log all metrics, parameters, artifacts, and the model to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 24: MLflow Logging with Signature"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC-ROC: 0.5410\n",
      "Test F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow_client = MlflowClient()\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # Log model architecture params\n",
    "    model_params = model.get_params()\n",
    "    mlflow.log_params(model_params)\n",
    "\n",
    "    # Batch log metrics\n",
    "    current_time = int(time.time() * 1000)\n",
    "    metrics_list = [\n",
    "        Metric(\"test_auc_roc\", auc_roc, current_time, 0),\n",
    "        Metric(\"test_auc_pr\", auc_pr, current_time, 0),\n",
    "        Metric(\"test_f1\", f1, current_time, 0),\n",
    "        Metric(\"test_precision\", precision, current_time, 0),\n",
    "        Metric(\"test_recall\", recall, current_time, 0),\n",
    "    ]\n",
    "\n",
    "    train_loss = trainer.callback_metrics.get(\"train_loss\")\n",
    "    val_loss = trainer.callback_metrics.get(\"val_loss\")\n",
    "    if train_loss is not None:\n",
    "        metrics_list.append(Metric(\"train_loss\", train_loss.item(), current_time, 0))\n",
    "    if val_loss is not None:\n",
    "        metrics_list.append(Metric(\"val_loss\", val_loss.item(), current_time, 0))\n",
    "\n",
    "    params_list = [\n",
    "        Param(\"batch_size\", str(BATCH_SIZE)),\n",
    "        Param(\"max_epochs\", str(trainer.max_epochs)),\n",
    "        Param(\"actual_epochs\", str(trainer.current_epoch)),\n",
    "        Param(\"early_stopping_patience\", str(10)),\n",
    "    ]\n",
    "\n",
    "    mlflow_client.log_batch(run_id, metrics=metrics_list, params=params_list)\n",
    "\n",
    "    print(f\"Test AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(f\"Test F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10. Pre-deployment Validation\n",
    "\n",
    "Validate that the registered model can be loaded and produces predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandSkippedException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:134)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:757)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:83)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:735)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:926)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:952)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:951)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:1006)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:777)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1037)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:957)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:522)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:806)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:806)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:769)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:751)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:283)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:283)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:415)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandSkippedException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:134)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:757)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:83)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:735)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:926)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:952)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:951)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:1006)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:777)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1037)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:957)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:522)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:806)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:806)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:769)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:751)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:283)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:283)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:415)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_uri = \"models:/m-24afa884e98d444fbd545903c849420b\"\n",
    "\n",
    "# Load and test with a sample batch\n",
    "loaded_model = mlflow.pytorch.load_model(model_uri)\n",
    "loaded_model.eval()\n",
    "\n",
    "sample_batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    sample_scores = loaded_model(\n",
    "        sample_batch[\"features\"], sample_batch[\"mask\"], sample_batch[\"market_type\"]\n",
    "    )\n",
    "\n",
    "print(f\"Sample predictions shape: {sample_scores.shape}\")\n",
    "print(f\"Sample scores: {sample_scores[:5].numpy()}\")\n",
    "print(f\"Sample labels: {sample_batch['label'][:5].numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33853421-d724-40f2-b9e5-49fad26ac2a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9. Hyperparameter Tuning with Optuna\n",
    "\n",
    "Search over model size, learning rate, dropout, and architecture choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "eaf3716c-c1b7-4517-9c98-a51a52ee9bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class PruningCallback(pl.Callback):\n",
    "    \"\"\"Prune unpromising Optuna trials during training.\"\"\"\n",
    "\n",
    "    def __init__(self, trial, monitor):\n",
    "        super().__init__()\n",
    "        self._trial = trial\n",
    "        self.monitor = monitor\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        current = trainer.callback_metrics.get(self.monitor)\n",
    "        if current is not None:\n",
    "            self._trial.report(current.item(), trainer.current_epoch)\n",
    "            if self._trial.should_prune():\n",
    "                raise optuna.TrialPruned(f\"Pruned at epoch {trainer.current_epoch}\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective: minimize validation loss.\"\"\"\n",
    "    # Search space\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 128])\n",
    "    n_heads = trial.suggest_categorical(\"n_heads\", [2, 4, 8])\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
    "    d_ff = trial.suggest_categorical(\"d_ff\", [128, 256, 512])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 5e-3, log=True)\n",
    "    wd = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    cross_start = trial.suggest_int(\"cross_attn_start_layer\", 0, max(0, n_layers - 1))\n",
    "\n",
    "    # Ensure d_model divisible by n_heads\n",
    "    if d_model % n_heads != 0:\n",
    "        raise optuna.TrialPruned(\"d_model not divisible by n_heads\")\n",
    "\n",
    "    with mlflow.start_run(nested=True) as child_run:\n",
    "        mlflow_client = MlflowClient()\n",
    "        run_id = child_run.info.run_id\n",
    "\n",
    "        param_dict = {\n",
    "            \"d_model\": d_model, \"n_heads\": n_heads, \"n_layers\": n_layers,\n",
    "            \"d_ff\": d_ff, \"dropout\": dropout, \"learning_rate\": lr,\n",
    "            \"weight_decay\": wd, \"cross_attn_start_layer\": cross_start,\n",
    "        }\n",
    "        params_list = [Param(k, str(v)) for k, v in param_dict.items()]\n",
    "\n",
    "        trial_model = ArbitrageLightningModule(\n",
    "            n_input_features=N_INPUT_FEATURES,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            n_layers=n_layers,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout,\n",
    "            learning_rate=lr,\n",
    "            weight_decay=wd,\n",
    "            cross_attn_start_layer=cross_start,\n",
    "        )\n",
    "\n",
    "        trial_trainer = pl.Trainer(\n",
    "            max_epochs=40,\n",
    "            callbacks=[\n",
    "                EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\"),\n",
    "                PruningCallback(trial, monitor=\"val_loss\"),\n",
    "            ],\n",
    "            enable_progress_bar=False,\n",
    "            log_every_n_steps=10,\n",
    "        )\n",
    "\n",
    "        trial_trainer.fit(trial_model, train_loader, val_loader)\n",
    "\n",
    "        best_val_loss = trial_trainer.callback_metrics.get(\"val_loss\").item()\n",
    "\n",
    "        current_time = int(time.time() * 1000)\n",
    "        mlflow_client.log_batch(\n",
    "            run_id,\n",
    "            metrics=[Metric(\"val_loss\", best_val_loss, current_time, 0)],\n",
    "            params=params_list,\n",
    "        )\n",
    "\n",
    "    trial.set_user_attr(\"model\", trial_model)\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Checkpoint for Local Inference\n",
    "\n",
    "Save the trained model as a `.ckpt` file that can be loaded by the FastAPI backend\n",
    "without any Databricks or MLflow dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`weights_only` was not set, defaulting to `False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to model.ckpt\n",
      "Copy it to Backend/models/model.ckpt for local FastAPI inference.\n"
     ]
    }
   ],
   "source": [
    "# Save the best checkpoint from the baseline trainer for local serving.\n",
    "# After running this cell, copy the file to Backend/models/model.ckpt\n",
    "#\n",
    "#   cp model.ckpt  ../Backend/models/model.ckpt\n",
    "\n",
    "trainer.save_checkpoint(\"model.ckpt\")\n",
    "print(f\"Checkpoint saved to model.ckpt\")\n",
    "print(\"Copy it to Backend/models/model.ckpt for local FastAPI inference.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "arbitrage_detection_notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "hacklytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}